{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import spacy\n",
    "import sklearn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# f = open('../../data/sentiment/positive')\n",
    "# pos = f.read()\n",
    "# f.close()\n",
    "\n",
    "# f = open('../../data/sentiment/negative')\n",
    "# neg = f.read()\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Spacy word embeddings\n",
    "word_embeddings = spacy.load('en', vectors='glove.6B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 300)\n"
     ]
    }
   ],
   "source": [
    "# Create a function to get vector format data for a sequence\n",
    "def sequence_to_data(seq, max_len=None):\n",
    "    seq = unicode(seq)\n",
    "    data = [word_embeddings(ix).vector for ix in seq.split()]\n",
    "    \n",
    "    if max_len is None:\n",
    "        max_len = len(data)\n",
    "    \n",
    "    data_mat = np.zeros((1, max_len, 300))\n",
    "    \n",
    "    for ix in range(min(len(data), max_len)):\n",
    "        data_mat[:, ix, :] = data[ix]\n",
    "    \n",
    "    return data_mat\n",
    "\n",
    "def seq_data_matrix(seq_data, max_len=None):\n",
    "    n_seq = len(seq_data)\n",
    "    data = np.concatenate([sequence_to_data(ix, max_len) for ix in seq_data], axis=0)\n",
    "    \n",
    "    return data\n",
    "    \n",
    "q = sequence_to_data(u'hello! what is the date today?', 100)\n",
    "print q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame([], columns=['text', 'score'])\n",
    "# for ix in pos.split('\\n'):\n",
    "#     text = ix.strip().lower()\n",
    "#     if len(text) > 1:\n",
    "#         df = df.append({'text': text, 'score': 1}, ignore_index=True)\n",
    "#     # print sequence_to_data(ix.strip().lower()).shape\n",
    "\n",
    "# for ix in neg.split('\\n'):\n",
    "#     text = ix.strip().lower()\n",
    "#     if len(text) > 1:\n",
    "#         df = df.append({'text': text, 'score': 0}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df = sklearn.utils.shuffle(df).reset_index(drop=True)\n",
    "# df = pd.read_csv('../../data/sentiment/dataset.csv', sep='|', index_col=0)\n",
    "df = pd.read_csv('../../imdb_tr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_Number</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2148</td>\n",
       "      <td>first think another Disney movie, might good, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23577</td>\n",
       "      <td>Put aside Dr. House repeat missed, Desperate H...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1319</td>\n",
       "      <td>big fan Stephen King's work, film made even gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13358</td>\n",
       "      <td>watched horrid thing TV. Needless say one movi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495</td>\n",
       "      <td>truly enjoyed film. acting terrific plot. Jeff...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_Number                                               text  polarity\n",
       "0        2148  first think another Disney movie, might good, ...         1\n",
       "1       23577  Put aside Dr. House repeat missed, Desperate H...         0\n",
       "2        1319  big fan Stephen King's work, film made even gr...         1\n",
       "3       13358  watched horrid thing TV. Needless say one movi...         0\n",
       "4        9495  truly enjoyed film. acting terrific plot. Jeff...         1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = pd.DataFrame([], columns=['x'])\n",
    "\n",
    "for ix in range(100):\n",
    "    a = a.append({'x': ix}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>x_sq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x  x_sq\n",
       "0  0.0   0.0\n",
       "1  1.0   1.0\n",
       "2  2.0   4.0\n",
       "3  3.0   9.0\n",
       "4  4.0  16.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['x_sq'] = a.x.apply(lambda x: x**2)\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['len'] = df['text'].str.split().apply(lambda x: len(x))\n",
    "# df = df.sort_index(ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_Number</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2148</td>\n",
       "      <td>first think another Disney movie, might good, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23577</td>\n",
       "      <td>Put aside Dr. House repeat missed, Desperate H...</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1319</td>\n",
       "      <td>big fan Stephen King's work, film made even gr...</td>\n",
       "      <td>1</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13358</td>\n",
       "      <td>watched horrid thing TV. Needless say one movi...</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495</td>\n",
       "      <td>truly enjoyed film. acting terrific plot. Jeff...</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_Number                                               text  polarity  \\\n",
       "0        2148  first think another Disney movie, might good, ...         1   \n",
       "1       23577  Put aside Dr. House repeat missed, Desperate H...         0   \n",
       "2        1319  big fan Stephen King's work, film made even gr...         1   \n",
       "3       13358  watched horrid thing TV. Needless say one movi...         0   \n",
       "4        9495  truly enjoyed film. acting terrific plot. Jeff...         1   \n",
       "\n",
       "   len  \n",
       "0   52  \n",
       "1   86  \n",
       "2  193  \n",
       "3   63  \n",
       "4   65  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.to_csv('../../data/sentiment/dataset.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a2658db46624>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2742\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2743\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2744\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "data = df\n",
    "data.text= data.text.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bucket_sizes = [[0, 10], [10, 15], [15, 20], [20, 25], [25, 45]]\n",
    "\n",
    "def assign_bucket(x):\n",
    "    for bucket in bucket_sizes:\n",
    "        if x > bucket[0] and x <= bucket[1]:\n",
    "            return bucket_sizes.index(bucket)\n",
    "    return len(bucket_sizes)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_Number</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>len</th>\n",
       "      <th>bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2148</td>\n",
       "      <td>first think another Disney movie, might good, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23577</td>\n",
       "      <td>Put aside Dr. House repeat missed, Desperate H...</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1319</td>\n",
       "      <td>big fan Stephen King's work, film made even gr...</td>\n",
       "      <td>1</td>\n",
       "      <td>193</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13358</td>\n",
       "      <td>watched horrid thing TV. Needless say one movi...</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495</td>\n",
       "      <td>truly enjoyed film. acting terrific plot. Jeff...</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_Number                                               text  polarity  \\\n",
       "0        2148  first think another Disney movie, might good, ...         1   \n",
       "1       23577  Put aside Dr. House repeat missed, Desperate H...         0   \n",
       "2        1319  big fan Stephen King's work, film made even gr...         1   \n",
       "3       13358  watched horrid thing TV. Needless say one movi...         0   \n",
       "4        9495  truly enjoyed film. acting terrific plot. Jeff...         1   \n",
       "\n",
       "   len  bucket  \n",
       "0   52       4  \n",
       "1   86       4  \n",
       "2  193       4  \n",
       "3   63       4  \n",
       "4   65       4  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['bucket'] = df.len.apply(assign_bucket)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_Number</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>len</th>\n",
       "      <th>bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>6408</td>\n",
       "      <td>Adrian Pasdar excellent film. makes fascinatin...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>4131</td>\n",
       "      <td>definitive movie version Hamlet. Branagh cuts ...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11303</th>\n",
       "      <td>12520</td>\n",
       "      <td>characters unlikeable script awful. It's waste...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19922</th>\n",
       "      <td>14807</td>\n",
       "      <td>Ming Merciless little Bardwork movie foul!</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16515</th>\n",
       "      <td>14666</td>\n",
       "      <td>without doubt worst movie ever seen. funny. in...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_Number                                               text  \\\n",
       "916          6408  Adrian Pasdar excellent film. makes fascinatin...   \n",
       "1114         4131  definitive movie version Hamlet. Branagh cuts ...   \n",
       "11303       12520  characters unlikeable script awful. It's waste...   \n",
       "19922       14807         Ming Merciless little Bardwork movie foul!   \n",
       "16515       14666  without doubt worst movie ever seen. funny. in...   \n",
       "\n",
       "       polarity  len  bucket  \n",
       "916           1    7       0  \n",
       "1114          1    9       0  \n",
       "11303         0    9       0  \n",
       "19922         0    6       0  \n",
       "16515         0    9       0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort(columns=['bucket'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_Number</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>len</th>\n",
       "      <th>bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>6408</td>\n",
       "      <td>Adrian Pasdar excellent film. makes fascinatin...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>4131</td>\n",
       "      <td>definitive movie version Hamlet. Branagh cuts ...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11303</th>\n",
       "      <td>12520</td>\n",
       "      <td>characters unlikeable script awful. It's waste...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19922</th>\n",
       "      <td>14807</td>\n",
       "      <td>Ming Merciless little Bardwork movie foul!</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16515</th>\n",
       "      <td>14666</td>\n",
       "      <td>without doubt worst movie ever seen. funny. in...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23292</th>\n",
       "      <td>16854</td>\n",
       "      <td>You'd better choose Paul Verhoeven's even watc...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8567</th>\n",
       "      <td>4996</td>\n",
       "      <td>don't know like movie well, never get tired wa...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12698</th>\n",
       "      <td>15633</td>\n",
       "      <td>Comment movie impossible. terrible, improbable...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11050</th>\n",
       "      <td>13568</td>\n",
       "      <td>movie terrible good effects.</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13588</th>\n",
       "      <td>19807</td>\n",
       "      <td>rating \"1\" begin express dull, depressing rele...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15527</th>\n",
       "      <td>16479</td>\n",
       "      <td>wouldn't rent one even dollar rental night.</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15364</th>\n",
       "      <td>23609</td>\n",
       "      <td>Long, boring, blasphemous. Never glad see endi...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_Number                                               text  \\\n",
       "916          6408  Adrian Pasdar excellent film. makes fascinatin...   \n",
       "1114         4131  definitive movie version Hamlet. Branagh cuts ...   \n",
       "11303       12520  characters unlikeable script awful. It's waste...   \n",
       "19922       14807         Ming Merciless little Bardwork movie foul!   \n",
       "16515       14666  without doubt worst movie ever seen. funny. in...   \n",
       "23292       16854  You'd better choose Paul Verhoeven's even watc...   \n",
       "8567         4996  don't know like movie well, never get tired wa...   \n",
       "12698       15633  Comment movie impossible. terrible, improbable...   \n",
       "11050       13568                       movie terrible good effects.   \n",
       "13588       19807  rating \"1\" begin express dull, depressing rele...   \n",
       "15527       16479        wouldn't rent one even dollar rental night.   \n",
       "15364       23609  Long, boring, blasphemous. Never glad see endi...   \n",
       "\n",
       "       polarity  len  bucket  \n",
       "916           1    7       0  \n",
       "1114          1    9       0  \n",
       "11303         0    9       0  \n",
       "19922         0    6       0  \n",
       "16515         0    9       0  \n",
       "23292         0    8       0  \n",
       "8567          1   10       0  \n",
       "12698         0   10       0  \n",
       "11050         0    4       0  \n",
       "13588         0   10       0  \n",
       "15527         0    7       0  \n",
       "15364         0    9       0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.bucket == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['score'] = df.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_batch(data, batch_size=10, gpu=True):\n",
    "    for bx in range(len(bucket_sizes)):\n",
    "        bucket_data = df[(df.bucket == bx)].reset_index(drop=True)\n",
    "        # print bx, bucket_sizes[bx][1], bucket_data.shape\n",
    "        \n",
    "        start = 0\n",
    "        stop = start + batch_size\n",
    "        \n",
    "        while start < bucket_data.shape[0]:\n",
    "            seq_length = bucket_sizes[bx][1]\n",
    "            section = bucket_data[start:stop]\n",
    "            X_data = seq_data_matrix(section.text, max_len=seq_length)\n",
    "            y_data = section.score\n",
    "            \n",
    "            if gpu:\n",
    "                yield Variable(torch.FloatTensor(X_data).cuda(), requires_grad=True), Variable(torch.LongTensor(y_data)).cuda()\n",
    "            else:\n",
    "                yield Variable(torch.FloatTensor(X_data), requires_grad=True), Variable(torch.LongTensor(y_data))\n",
    "            \n",
    "            start = stop\n",
    "            stop = start + batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Prisons exactly renowned kind hospitality 'happy vibes', stories fights, chaos, murder course extreme male bonding! prison film different beast altogether. Horror films set cells are, probably know, nothing particularly new emphasis exaggerate fear claustrophobia inability escape \\xc2? two greatest themes horror cinema. examples CHAIR (Waldermar Korzeniowsky, 1988), GREEN MILE (Frank Darabont, 1999), ALIEN 3 (David Fincher, 1992)and course entire Women Prison exploitation genre itself, another entry niche something inventive lot fun boot order recognised. least that's you'd thought. PRISON certainly incredibly fun enjoyable ride it's somewhat shame isn't well known be.<br /><br />The film, short, centres old prison (well, duh!) reopened. However, it's fellow inmates guards prisoners fear, also mean ass demon ghost spirit one thing mind; death! boy, treated awesome death scenes! won't spoil anything plenty innovative enjoyable murders done invisible hands.<br /><br />Besides special effects murders, film also another thing going it; it's cast. Headlining, LORD RINGS (Peter Jackson, 2001-2003) star Viggo Mortensen (and inclined, yes, get naked) whose performance highly believable, done skill Eastwood-esquire character bad-to-the-bone likable (a delicate mix). Add cast 'hey-wait-a-minute-I-know-that-guy' actors you've got one great set stars. characters however lack three-dimensionality often come across stereotypical. We've got black oculist, hard-as-nails prison warden, human-rights activist woman plenty stock characters. honesty, 'fault' actually aids film. Instead boring character development over-long equilibrium, chucked, less, straight action gets going (very early on) there's single scene that's filler \\xc2? it's balls wall plot. Unlike certain SHAWSHANK REDEMPTION (Frank Darabont, 1994 )! Sharing conventions slasher genre, somewhat convention itself, and, good ol' slasher genre tradition, PRISON punishes bad.<br /><br />All excellent little horror film one sadly overlooked unmentioned among horror world. excellent cast great special effects rather original death scenes film highly recommended horror fans. Don't fooled thinking it'll cheesy little film either, made USA 1980s, it's far cheesy (although end ruin this) and, simultaneously, far gritty realistic (whilst attempts tackle issues prison rape, rather subtly done).<br /><br />I give 3.5 5 luvs. entertaining horror film nice touches indeed.\"]\n",
      "89\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Issue replicated\n",
    "s = df.text\n",
    "\n",
    "for x in range(len(s)):\n",
    "    sx = s[x]\n",
    "    try:\n",
    "        q = unicode(sx.decode('utf-8'))\n",
    "    except:\n",
    "        print [sx]\n",
    "        print x\n",
    "        print '-'*80\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 10, 300]) torch.Size([12])\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xc2 in position 13: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-f38197cf983d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miy\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmake_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-b7f6d007d631>\u001b[0m in \u001b[0;36mmake_batch\u001b[0;34m(data, batch_size, gpu)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbucket_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbucket_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mX_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_data_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0my_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-3c080a3ac186>\u001b[0m in \u001b[0;36mseq_data_matrix\u001b[0;34m(seq_data, max_len)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mseq_data_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mn_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msequence_to_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-3c080a3ac186>\u001b[0m in \u001b[0;36msequence_to_data\u001b[0;34m(seq, max_len)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create a function to get vector format data for a sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msequence_to_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xc2 in position 13: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "for ix, iy in make_batch(df, batch_size=1000, gpu=False):\n",
    "    print ix.shape, iy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df.head(10)\n",
    "# Printing colored text (Useful later)\n",
    "# print colored(\"hello red world\", 'blue')# print 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SeqModel(nn.Module):\n",
    "    def __init__(self, in_shape=None, out_shape=None, hidden_shape=None):\n",
    "        super(SeqModel, self).__init__()\n",
    "        self.in_shape = in_shape\n",
    "        self.out_shape = out_shape\n",
    "        self.hidden_shape = hidden_shape\n",
    "        self.n_layers = 1\n",
    "        \n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=self.in_shape,\n",
    "            hidden_size=self.hidden_shape,\n",
    "            num_layers=self.n_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.lin = nn.Linear(self.hidden_shape, 64)\n",
    "        self.dropout = nn.Dropout(0.42)\n",
    "        self.out = nn.Linear(64, self.out_shape)\n",
    "    \n",
    "    def forward(self, x, h):\n",
    "        r_out, h_state = self.rnn(x, h)\n",
    "        last_out = r_out[:, -1, :]\n",
    "        y = F.tanh(self.lin(last_out))\n",
    "        y = self.dropout(y)\n",
    "        y = F.softmax(self.out(y))\n",
    "        return y\n",
    "    \n",
    "    def predict(self, x):\n",
    "        h_state = self.init_hidden(1, gpu=False)\n",
    "        \n",
    "        x = sequence_to_data(x)\n",
    "        pred = self.forward(torch.FloatTensor(x), h_state)\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def get_embedding(self, x):\n",
    "        h_state = self.init_hidden(1, gpu=False)\n",
    "        \n",
    "        x = sequence_to_data(x)\n",
    "        r_out, h = self.rnn(torch.FloatTensor(x), h_state)\n",
    "        last_out = r_out[:, -1, :]\n",
    "        \n",
    "        return last_out.data.numpy()\n",
    "            \n",
    "    def init_hidden(self, batch_size, gpu=True):\n",
    "        if gpu:\n",
    "            return (Variable(torch.zeros(self.n_layers, batch_size, self.hidden_shape).cuda()),\n",
    "                    Variable(torch.zeros(self.n_layers, batch_size, self.hidden_shape)).cuda())\n",
    "        return (Variable(torch.zeros(self.n_layers, batch_size, self.hidden_shape)),\n",
    "                Variable(torch.zeros(self.n_layers, batch_size, self.hidden_shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeqModel(\n",
      "  (rnn): LSTM(300, 256, batch_first=True)\n",
      "  (lin): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (dropout): Dropout(p=0.42)\n",
      "  (out): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SeqModel(\n",
       "  (rnn): LSTM(300, 256, batch_first=True)\n",
       "  (lin): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (dropout): Dropout(p=0.42)\n",
       "  (out): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SeqModel(in_shape=300, hidden_shape=256, out_shape=2)\n",
    "\n",
    "print model\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.predict('hello bad world')\n",
    "\n",
    "# Load the model\n",
    "model.load_state_dict(torch.load('/home/shubham/all_projects/CB/Summer_2018/data/checkpoints/seq_lstm_bucket/model_256h_epoch_700.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.69742333889 at Epoch: 0 | Step: 0\n",
      "Loss: 0.69163531065 at Epoch: 0 | Step: 20\n",
      "Loss: 0.692053377628 at Epoch: 0 | Step: 40\n",
      "Overall Average Loss: 0.694422006607 at Epoch: 0\n",
      "Loss: 0.692090451717 at Epoch: 1 | Step: 0\n",
      "Loss: 0.687447428703 at Epoch: 1 | Step: 20\n",
      "Loss: 0.689199209213 at Epoch: 1 | Step: 40\n",
      "Overall Average Loss: 0.689712703228 at Epoch: 1\n",
      "Loss: 0.681926727295 at Epoch: 2 | Step: 0\n",
      "Loss: 0.668727934361 at Epoch: 2 | Step: 20\n",
      "Loss: 0.647350132465 at Epoch: 2 | Step: 40\n",
      "Overall Average Loss: 0.674889683723 at Epoch: 2\n",
      "Loss: 0.63601154089 at Epoch: 3 | Step: 0\n",
      "Loss: 0.608234405518 at Epoch: 3 | Step: 20\n",
      "Loss: 0.593071639538 at Epoch: 3 | Step: 40\n",
      "Overall Average Loss: 0.638657689095 at Epoch: 3\n",
      "Loss: 0.577009916306 at Epoch: 4 | Step: 0\n",
      "Loss: 0.578892111778 at Epoch: 4 | Step: 20\n",
      "Loss: 0.581489622593 at Epoch: 4 | Step: 40\n",
      "Overall Average Loss: 0.612688839436 at Epoch: 4\n",
      "Loss: 0.549013614655 at Epoch: 5 | Step: 0\n",
      "Loss: 0.570038259029 at Epoch: 5 | Step: 20\n",
      "Loss: 0.575555443764 at Epoch: 5 | Step: 40\n",
      "Overall Average Loss: 0.593836128712 at Epoch: 5\n",
      "Loss: 0.526914358139 at Epoch: 6 | Step: 0\n",
      "Loss: 0.56396317482 at Epoch: 6 | Step: 20\n",
      "Loss: 0.570190310478 at Epoch: 6 | Step: 40\n",
      "Overall Average Loss: 0.584912419319 at Epoch: 6\n",
      "Loss: 0.51433557272 at Epoch: 7 | Step: 0\n",
      "Loss: 0.557445347309 at Epoch: 7 | Step: 20\n",
      "Loss: 0.571662664413 at Epoch: 7 | Step: 40\n",
      "Overall Average Loss: 0.582174420357 at Epoch: 7\n",
      "Loss: 0.525627613068 at Epoch: 8 | Step: 0\n",
      "Loss: 0.543232917786 at Epoch: 8 | Step: 20\n",
      "Loss: 0.556832849979 at Epoch: 8 | Step: 40\n",
      "Overall Average Loss: 0.57739084959 at Epoch: 8\n",
      "Loss: 0.525994777679 at Epoch: 9 | Step: 0\n",
      "Loss: 0.545738399029 at Epoch: 9 | Step: 20\n",
      "Loss: 0.544856071472 at Epoch: 9 | Step: 40\n",
      "Overall Average Loss: 0.570654571056 at Epoch: 9\n",
      "Loss: 0.513692259789 at Epoch: 10 | Step: 0\n",
      "Loss: 0.541399240494 at Epoch: 10 | Step: 20\n",
      "Loss: 0.542103528976 at Epoch: 10 | Step: 40\n",
      "Overall Average Loss: 0.563399195671 at Epoch: 10\n",
      "Loss: 0.505694925785 at Epoch: 11 | Step: 0\n",
      "Loss: 0.533120155334 at Epoch: 11 | Step: 20\n",
      "Loss: 0.536459207535 at Epoch: 11 | Step: 40\n",
      "Overall Average Loss: 0.557379901409 at Epoch: 11\n",
      "Loss: 0.493396878242 at Epoch: 12 | Step: 0\n",
      "Loss: 0.526925086975 at Epoch: 12 | Step: 20\n",
      "Loss: 0.531074225903 at Epoch: 12 | Step: 40\n",
      "Overall Average Loss: 0.551092982292 at Epoch: 12\n",
      "Loss: 0.489806681871 at Epoch: 13 | Step: 0\n",
      "Loss: 0.519273877144 at Epoch: 13 | Step: 20\n",
      "Loss: 0.519293963909 at Epoch: 13 | Step: 40\n",
      "Overall Average Loss: 0.545694589615 at Epoch: 13\n",
      "Loss: 0.48345375061 at Epoch: 14 | Step: 0\n",
      "Loss: 0.51608812809 at Epoch: 14 | Step: 20\n",
      "Loss: 0.513243317604 at Epoch: 14 | Step: 40\n",
      "Overall Average Loss: 0.541397333145 at Epoch: 14\n",
      "Loss: 0.481462657452 at Epoch: 15 | Step: 0\n",
      "Loss: 0.510341882706 at Epoch: 15 | Step: 20\n",
      "Loss: 0.511853575706 at Epoch: 15 | Step: 40\n",
      "Overall Average Loss: 0.537546873093 at Epoch: 15\n",
      "Loss: 0.480911433697 at Epoch: 16 | Step: 0\n",
      "Loss: 0.513807117939 at Epoch: 16 | Step: 20\n",
      "Loss: 0.509938836098 at Epoch: 16 | Step: 40\n",
      "Overall Average Loss: 0.534784376621 at Epoch: 16\n",
      "Loss: 0.47408130765 at Epoch: 17 | Step: 0\n",
      "Loss: 0.50886631012 at Epoch: 17 | Step: 20\n",
      "Loss: 0.510581076145 at Epoch: 17 | Step: 40\n",
      "Overall Average Loss: 0.530485510826 at Epoch: 17\n",
      "Loss: 0.470617681742 at Epoch: 18 | Step: 0\n",
      "Loss: 0.505066335201 at Epoch: 18 | Step: 20\n",
      "Loss: 0.51499325037 at Epoch: 18 | Step: 40\n",
      "Overall Average Loss: 0.52730178833 at Epoch: 18\n",
      "Loss: 0.46736240387 at Epoch: 19 | Step: 0\n",
      "Loss: 0.505021572113 at Epoch: 19 | Step: 20\n",
      "Loss: 0.512701034546 at Epoch: 19 | Step: 40\n",
      "Overall Average Loss: 0.524192869663 at Epoch: 19\n",
      "Loss: 0.470387965441 at Epoch: 20 | Step: 0\n",
      "Loss: 0.504788458347 at Epoch: 20 | Step: 20\n",
      "Loss: 0.508899629116 at Epoch: 20 | Step: 40\n",
      "Overall Average Loss: 0.523307919502 at Epoch: 20\n",
      "Loss: 0.464465528727 at Epoch: 21 | Step: 0\n",
      "Loss: 0.507555365562 at Epoch: 21 | Step: 20\n",
      "Loss: 0.515251517296 at Epoch: 21 | Step: 40\n",
      "Overall Average Loss: 0.52463054657 at Epoch: 21\n",
      "Loss: 0.469170838594 at Epoch: 22 | Step: 0\n",
      "Loss: 0.501567602158 at Epoch: 22 | Step: 20\n",
      "Loss: 0.50456982851 at Epoch: 22 | Step: 40\n",
      "Overall Average Loss: 0.526973605156 at Epoch: 22\n",
      "Loss: 0.485012233257 at Epoch: 23 | Step: 0\n",
      "Loss: 0.498085379601 at Epoch: 23 | Step: 20\n",
      "Loss: 0.495019763708 at Epoch: 23 | Step: 40\n",
      "Overall Average Loss: 0.523140490055 at Epoch: 23\n",
      "Loss: 0.466693073511 at Epoch: 24 | Step: 0\n",
      "Loss: 0.485822230577 at Epoch: 24 | Step: 20\n",
      "Loss: 0.494245409966 at Epoch: 24 | Step: 40\n",
      "Overall Average Loss: 0.514452755451 at Epoch: 24\n",
      "Loss: 0.471115678549 at Epoch: 25 | Step: 0\n",
      "Loss: 0.483766198158 at Epoch: 25 | Step: 20\n",
      "Loss: 0.489568740129 at Epoch: 25 | Step: 40\n",
      "Overall Average Loss: 0.512136101723 at Epoch: 25\n",
      "Loss: 0.474546521902 at Epoch: 26 | Step: 0\n",
      "Loss: 0.48164254427 at Epoch: 26 | Step: 20\n",
      "Loss: 0.486355632544 at Epoch: 26 | Step: 40\n",
      "Overall Average Loss: 0.511702656746 at Epoch: 26\n",
      "Loss: 0.477392196655 at Epoch: 27 | Step: 0\n",
      "Loss: 0.495191037655 at Epoch: 27 | Step: 20\n",
      "Loss: 0.496343642473 at Epoch: 27 | Step: 40\n",
      "Overall Average Loss: 0.518317103386 at Epoch: 27\n",
      "Loss: 0.456563651562 at Epoch: 28 | Step: 0\n",
      "Loss: 0.484345287085 at Epoch: 28 | Step: 20\n",
      "Loss: 0.490119546652 at Epoch: 28 | Step: 40\n",
      "Overall Average Loss: 0.513072371483 at Epoch: 28\n",
      "Loss: 0.451302081347 at Epoch: 29 | Step: 0\n",
      "Loss: 0.479845076799 at Epoch: 29 | Step: 20\n",
      "Loss: 0.487130314112 at Epoch: 29 | Step: 40\n",
      "Overall Average Loss: 0.506174564362 at Epoch: 29\n",
      "Loss: 0.451211124659 at Epoch: 30 | Step: 0\n",
      "Loss: 0.475132018328 at Epoch: 30 | Step: 20\n",
      "Loss: 0.484574496746 at Epoch: 30 | Step: 40\n",
      "Overall Average Loss: 0.502227902412 at Epoch: 30\n",
      "Loss: 0.451631844044 at Epoch: 31 | Step: 0\n",
      "Loss: 0.475101321936 at Epoch: 31 | Step: 20\n",
      "Loss: 0.487421482801 at Epoch: 31 | Step: 40\n",
      "Overall Average Loss: 0.498895674944 at Epoch: 31\n",
      "Loss: 0.447932511568 at Epoch: 32 | Step: 0\n",
      "Loss: 0.474938631058 at Epoch: 32 | Step: 20\n",
      "Loss: 0.484663814306 at Epoch: 32 | Step: 40\n",
      "Overall Average Loss: 0.497542649508 at Epoch: 32\n",
      "Loss: 0.444742619991 at Epoch: 33 | Step: 0\n",
      "Loss: 0.471693068743 at Epoch: 33 | Step: 20\n",
      "Loss: 0.484110414982 at Epoch: 33 | Step: 40\n",
      "Overall Average Loss: 0.493412494659 at Epoch: 33\n",
      "Loss: 0.442980676889 at Epoch: 34 | Step: 0\n",
      "Loss: 0.467999815941 at Epoch: 34 | Step: 20\n",
      "Loss: 0.478754997253 at Epoch: 34 | Step: 40\n",
      "Overall Average Loss: 0.492076158524 at Epoch: 34\n",
      "Loss: 0.440233498812 at Epoch: 35 | Step: 0\n",
      "Loss: 0.470312267542 at Epoch: 35 | Step: 20\n",
      "Loss: 0.476249724627 at Epoch: 35 | Step: 40\n",
      "Overall Average Loss: 0.489179372787 at Epoch: 35\n",
      "Loss: 0.439033806324 at Epoch: 36 | Step: 0\n",
      "Loss: 0.469206631184 at Epoch: 36 | Step: 20\n",
      "Loss: 0.475227326155 at Epoch: 36 | Step: 40\n",
      "Overall Average Loss: 0.49189427495 at Epoch: 36\n",
      "Loss: 0.436659693718 at Epoch: 37 | Step: 0\n",
      "Loss: 0.491647422314 at Epoch: 37 | Step: 20\n",
      "Loss: 0.472197830677 at Epoch: 37 | Step: 40\n",
      "Overall Average Loss: 0.505670905113 at Epoch: 37\n",
      "Loss: 0.457237482071 at Epoch: 38 | Step: 0\n",
      "Loss: 0.466650813818 at Epoch: 38 | Step: 20\n",
      "Loss: 0.481216132641 at Epoch: 38 | Step: 40\n",
      "Overall Average Loss: 0.500137031078 at Epoch: 38\n",
      "Loss: 0.47481316328 at Epoch: 39 | Step: 0\n",
      "Loss: 0.467495381832 at Epoch: 39 | Step: 20\n",
      "Loss: 0.470978289843 at Epoch: 39 | Step: 40\n",
      "Overall Average Loss: 0.496206909418 at Epoch: 39\n",
      "Loss: 0.461064308882 at Epoch: 40 | Step: 0\n",
      "Loss: 0.464761227369 at Epoch: 40 | Step: 20\n",
      "Loss: 0.46520626545 at Epoch: 40 | Step: 40\n",
      "Overall Average Loss: 0.491576761007 at Epoch: 40\n",
      "Loss: 0.469571202993 at Epoch: 41 | Step: 0\n",
      "Loss: 0.459188580513 at Epoch: 41 | Step: 20\n",
      "Loss: 0.462537109852 at Epoch: 41 | Step: 40\n",
      "Overall Average Loss: 0.486786901951 at Epoch: 41\n",
      "Loss: 0.469054400921 at Epoch: 42 | Step: 0\n",
      "Loss: 0.459449231625 at Epoch: 42 | Step: 20\n",
      "Loss: 0.463728100061 at Epoch: 42 | Step: 40\n",
      "Overall Average Loss: 0.484697341919 at Epoch: 42\n",
      "Loss: 0.457308411598 at Epoch: 43 | Step: 0\n",
      "Loss: 0.455283880234 at Epoch: 43 | Step: 20\n",
      "Loss: 0.461940914392 at Epoch: 43 | Step: 40\n",
      "Overall Average Loss: 0.485280305147 at Epoch: 43\n",
      "Loss: 0.457079768181 at Epoch: 44 | Step: 0\n",
      "Loss: 0.451515763998 at Epoch: 44 | Step: 20\n",
      "Loss: 0.457645446062 at Epoch: 44 | Step: 40\n",
      "Overall Average Loss: 0.482401043177 at Epoch: 44\n",
      "Loss: 0.455950021744 at Epoch: 45 | Step: 0\n",
      "Loss: 0.45035892725 at Epoch: 45 | Step: 20\n",
      "Loss: 0.46109944582 at Epoch: 45 | Step: 40\n",
      "Overall Average Loss: 0.482721477747 at Epoch: 45\n",
      "Loss: 0.450999975204 at Epoch: 46 | Step: 0\n",
      "Loss: 0.457892537117 at Epoch: 46 | Step: 20\n",
      "Loss: 0.473802834749 at Epoch: 46 | Step: 40\n",
      "Overall Average Loss: 0.484114319086 at Epoch: 46\n",
      "Loss: 0.439380735159 at Epoch: 47 | Step: 0\n",
      "Loss: 0.456071287394 at Epoch: 47 | Step: 20\n",
      "Loss: 0.470109641552 at Epoch: 47 | Step: 40\n",
      "Overall Average Loss: 0.479265272617 at Epoch: 47\n",
      "Loss: 0.43844383955 at Epoch: 48 | Step: 0\n",
      "Loss: 0.446683079004 at Epoch: 48 | Step: 20\n",
      "Loss: 0.470870375633 at Epoch: 48 | Step: 40\n",
      "Overall Average Loss: 0.478016227484 at Epoch: 48\n",
      "Loss: 0.448094546795 at Epoch: 49 | Step: 0\n",
      "Loss: 0.448546677828 at Epoch: 49 | Step: 20\n",
      "Loss: 0.494729071856 at Epoch: 49 | Step: 40\n",
      "Overall Average Loss: 0.481781721115 at Epoch: 49\n"
     ]
    }
   ],
   "source": [
    "# Set to train mode\n",
    "# model.cuda()\n",
    "model.train()\n",
    "\n",
    "for epoch in range(50):\n",
    "    total_loss = 0\n",
    "    N = 0\n",
    "    for step, (b_x, b_y) in enumerate(make_batch(df, batch_size=200)):\n",
    "        # print step, b_x.shape, b_y.shape\n",
    "        bsize = b_x.size(0)\n",
    "        \n",
    "        h_state = model.init_hidden(bsize, gpu=True)\n",
    "\n",
    "        pred = model(b_x, h_state)\n",
    "        loss = criterion(pred, b_y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss\n",
    "        N += 1.0\n",
    "        if step%20 == 0:\n",
    "            print 'Loss: {} at Epoch: {} | Step: {}'.format(loss, epoch, step)\n",
    "        \n",
    "    print \"Overall Average Loss: {} at Epoch: {}\".format(total_loss / float(N), epoch)\n",
    "    \n",
    "    # Save model checkpoints\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(model.state_dict(), \"/home/shubham/all_projects/CB/Summer_2018/data/checkpoints/seq_lstm_bucket/model_256h_epoch_{}.ckpt\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeqModel(\n",
       "  (rnn): LSTM(300, 256, batch_first=True)\n",
       "  (lin): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (dropout): Dropout(p=0.42)\n",
       "  (out): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make ppredictions\n",
    "model.eval()\n",
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00,  1.3468e-15]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict('I am going to some place to take play a game')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256) (1, 256)\n"
     ]
    }
   ],
   "source": [
    "model.cpu()\n",
    "\n",
    "v1 = model.get_embedding('I am going to a place')\n",
    "v2 = model.get_embedding('I am not going')\n",
    "print v1.shape, v2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7183737]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.pairwise.cosine_distances(v1, v2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
